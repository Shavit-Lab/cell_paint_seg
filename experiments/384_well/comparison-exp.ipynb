{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu, pearsonr\n",
    "from tqdm import tqdm\n",
    "from cell_paint_seg.utils import get_id_to_path\n",
    "from cell_paint_seg.image_io import read_ims, read_seg\n",
    "from skimage import exposure, measure\n",
    "import umap\n",
    "import umap.plot\n",
    "from graspologic.plot import heatmap\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [\"Brightfield\", \"ER\", \"AGP\", \"Mito\", \"DNA\", \"RNA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get remote info for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_path_im_0 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142687__2024-03-29T18_18_57-Measurement 1/Images/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")\n",
    "id_to_path_seg_0 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142687__2024-03-29T18_18_57-Measurement 1/segmentations/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")\n",
    "\n",
    "id_to_path_im_1 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142688__2024-03-29T19_57_13-Measurement 1/Images/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")\n",
    "id_to_path_seg_1 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142688__2024-03-29T19_57_13-Measurement 1/segmentations_v1/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(id, id_to_path_im, id_to_path_seg):\n",
    "    paths_ims = id_to_path_im[0][id]\n",
    "    paths_segs = id_to_path_seg[0][id]\n",
    "\n",
    "    images = read_ims(paths_ims, sftp_client=id_to_path_im[1])\n",
    "    segs = read_ims(paths_segs, sftp_client=id_to_path_seg[1])\n",
    "\n",
    "    image_dna = images[channels.index(\"DNA\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_dna_adj = exposure.equalize_adapthist(\n",
    "        image_dna, clip_limit=0.03, kernel_size=[s // 64 for s in image_dna.shape]\n",
    "    )\n",
    "    image_rna = images[channels.index(\"RNA\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_rna_adj = exposure.equalize_adapthist(image_rna, clip_limit=0.03)\n",
    "    image_agp = images[channels.index(\"AGP\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_agp_adj = exposure.equalize_adapthist(image_agp, clip_limit=0.03)\n",
    "    image_rgb = np.stack([image_agp, image_rna, image_dna], axis=2)\n",
    "    image_rgb_adj = np.stack([image_agp_adj, image_rna_adj, image_dna_adj], axis=2)\n",
    "\n",
    "    seg_cell, seg_soma, seg_nuc = segs\n",
    "    seg_cyto = np.logical_and(seg_soma > 0, seg_nuc == 0)\n",
    "\n",
    "    seg_cell_masked = np.ma.masked_array(seg_cell, mask=seg_cell == 0)\n",
    "    seg_soma_masked = np.ma.masked_array(seg_soma, mask=seg_soma == 0)\n",
    "    seg_nuc_masked = np.ma.masked_array(seg_nuc, mask=seg_nuc == 0)\n",
    "    seg_cyto_masked = np.ma.masked_array(seg_cyto, mask=seg_cyto == 0)\n",
    "\n",
    "    f, axs = plt.subplots(nrows=1, ncols=3, dpi=300)\n",
    "\n",
    "    axs[0].imshow(image_rgb, cmap=\"gray\")\n",
    "    axs[0].set_title(f\"Image {id}\")\n",
    "    axs[1].imshow(image_rgb_adj, cmap=\"gray\")\n",
    "    axs[2].imshow(image_dna, cmap=\"gray\")\n",
    "    axs[2].imshow(seg_cell_masked % 20, cmap=\"tab20\", alpha=1)\n",
    "    axs[2].imshow(seg_cyto_masked, cmap=\"Accent\", alpha=1)\n",
    "    axs[2].imshow(seg_nuc_masked > 0, cmap=\"Set1\", alpha=1)\n",
    "\n",
    "    # axs[2].imshow(image_rgb_adj, cmap=\"gray\")\n",
    "    # axs[2].imshow(seg_soma_masked % 20, cmap=\"tab20\", alpha=1)\n",
    "    f.set_figheight(10)\n",
    "    f.set_figwidth(30)\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    f.savefig(\n",
    "        \"/Users/thomasathey/Documents/shavit-lab/fraenkel/presentation/answer-als/example/hierch-example-colors.svg\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fields(id, id_to_path_im, id_to_path_seg):\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=3, dpi=300, figsize=(8, 8))\n",
    "\n",
    "    for f in range(9):\n",
    "        new_id = f\"{id[:8]}{f+1}{id[-3:]}\"\n",
    "\n",
    "        paths_ims = id_to_path_im[0][new_id]\n",
    "        paths_segs = id_to_path_seg[0][new_id]\n",
    "\n",
    "        images = read_ims(paths_ims, sftp_client=id_to_path_im[1])\n",
    "        segs = read_ims(paths_segs, sftp_client=id_to_path_seg[1])\n",
    "\n",
    "        image_dna = images[channels.index(\"DNA\")].astype(\"float\") / (2**16 - 1)\n",
    "        image_dna_adj = exposure.equalize_adapthist(\n",
    "            image_dna, clip_limit=0.03, kernel_size=[s // 64 for s in image_dna.shape]\n",
    "        )\n",
    "        image_rna = images[channels.index(\"RNA\")].astype(\"float\") / (2**16 - 1)\n",
    "        image_rna_adj = exposure.equalize_adapthist(image_rna, clip_limit=0.03)\n",
    "        image_agp = images[channels.index(\"AGP\")].astype(\"float\") / (2**16 - 1)\n",
    "        image_agp_adj = exposure.equalize_adapthist(image_agp, clip_limit=0.03)\n",
    "        image_rgb = np.stack([image_agp, image_rna, image_dna], axis=2)\n",
    "        image_rgb_adj = np.stack([image_agp_adj, image_rna_adj, image_dna_adj], axis=2)\n",
    "\n",
    "        seg_cell, seg_soma, seg_nuc = segs\n",
    "        seg_soma_masked = np.ma.masked_array(seg_soma, mask=seg_soma == 0)\n",
    "        for lbl in np.unique(seg_nuc):\n",
    "            if lbl == 0:\n",
    "                continue\n",
    "            soma_area = np.sum(seg_soma == lbl)\n",
    "            ratio = np.sum(seg_nuc == lbl) / soma_area\n",
    "            if ratio >= 0.9 or soma_area < 278:\n",
    "                seg_soma_masked = np.ma.masked_array(\n",
    "                    seg_soma_masked, mask=seg_soma_masked == lbl\n",
    "                )\n",
    "            else:\n",
    "                pass  # seg_soma_masked = np.ma.masked_array(seg_soma_masked, mask=seg_soma_masked == lbl)\n",
    "        seg_soma_masked[0, 0] = 0\n",
    "\n",
    "        axs[f // 3, f % 3].imshow(image_rgb_adj, cmap=\"gray\")\n",
    "        axs[f // 3, f % 3].imshow(seg_soma_masked % 20, cmap=\"tab20\")\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.axis(\"off\")\n",
    "    # fig.suptitle(f\"Image {id}\")\n",
    "\n",
    "    # fig.tight_layout()\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(id, id_to_path_im, id_to_path_seg):\n",
    "    paths_ims = id_to_path_im[0][id]\n",
    "    paths_segs = id_to_path_seg[0][id]\n",
    "\n",
    "    images = read_ims(paths_ims, sftp_client=id_to_path_im[1])\n",
    "    segs = read_ims(paths_segs, sftp_client=id_to_path_seg[1])\n",
    "\n",
    "    image_dna = images[channels.index(\"DNA\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_dna_adj = exposure.equalize_adapthist(\n",
    "        image_dna, clip_limit=0.03, kernel_size=[s // 64 for s in image_dna.shape]\n",
    "    )\n",
    "    image_rna = images[channels.index(\"RNA\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_rna_adj = exposure.equalize_adapthist(image_rna, clip_limit=0.03)\n",
    "    image_agp = images[channels.index(\"AGP\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_agp_adj = exposure.equalize_adapthist(image_agp, clip_limit=0.03)\n",
    "    image_rgb_adj = np.stack([image_agp_adj, image_rna_adj, image_dna_adj], axis=2)\n",
    "\n",
    "    seg_cell, seg_soma, seg_nuc = segs\n",
    "    seg_cyto = np.logical_and(seg_soma > 0, seg_nuc == 0)\n",
    "\n",
    "    features = np.zeros_like(seg_soma, dtype=\"float\")\n",
    "    for lbl in np.unique(seg_nuc):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "        feature = np.sum(seg_nuc == lbl) / np.sum(seg_soma == lbl)\n",
    "        feature = np.sum(seg_soma == lbl)\n",
    "        features[seg_soma == lbl] = feature\n",
    "\n",
    "    features_masked = np.ma.masked_array(features, mask=features == 0)\n",
    "\n",
    "    f, axs = plt.subplots(nrows=1, ncols=2, dpi=300)\n",
    "\n",
    "    axs[0].imshow(image_rgb_adj, cmap=\"gray\")\n",
    "    axs[0].set_title(f\"Image {id}\")\n",
    "    axs[1].imshow(image_dna, cmap=\"gray\")\n",
    "    im = axs[1].imshow(features_masked, cmap=\"autumn\", alpha=1)\n",
    "    plt.colorbar(im, ax=axs[1])\n",
    "    f.set_figheight(10)\n",
    "    f.set_figwidth(20)\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_crop(id, id_to_path_im, id_to_path_seg):\n",
    "    paths_ims = id_to_path_im[0][id]\n",
    "    paths_segs = id_to_path_seg[0][id]\n",
    "\n",
    "    images = read_ims(paths_ims, sftp_client=id_to_path_im[1])\n",
    "    segs = read_ims(paths_segs, sftp_client=id_to_path_seg[1])\n",
    "\n",
    "    image_dna = images[channels.index(\"DNA\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_dna_adj = exposure.equalize_adapthist(\n",
    "        image_dna, clip_limit=0.03, kernel_size=[s // 64 for s in image_dna.shape]\n",
    "    )\n",
    "    image_rna = images[channels.index(\"RNA\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_rna_adj = exposure.equalize_adapthist(image_rna, clip_limit=0.03)\n",
    "    image_agp = images[channels.index(\"AGP\")].astype(\"float\") / (2**16 - 1)\n",
    "    image_agp_adj = exposure.equalize_adapthist(image_agp, clip_limit=0.03)\n",
    "    image_rgb = np.stack([image_agp, image_rna, image_dna], axis=2)\n",
    "    image_rgb_adj = np.stack([image_agp_adj, image_rna_adj, image_dna_adj], axis=2)\n",
    "\n",
    "    seg_cell, seg_soma, seg_nuc = segs\n",
    "    seg_cyto = np.logical_and(seg_soma > 0, seg_nuc == 0)\n",
    "\n",
    "    seg_cell_masked = np.ma.masked_array(seg_cell, mask=seg_cell == 0)\n",
    "    seg_soma_masked = np.ma.masked_array(seg_soma, mask=seg_soma == 0)\n",
    "    seg_nuc_masked = np.ma.masked_array(seg_nuc, mask=seg_nuc == 0)\n",
    "    seg_cyto_masked = np.ma.masked_array(seg_cyto, mask=seg_cyto == 0)\n",
    "\n",
    "    soma_id = random.choice(np.unique(seg_soma))\n",
    "    mask = measure.label(seg_soma == soma_id)\n",
    "    bbox = measure.regionprops(mask)[0].bbox\n",
    "    crop = image_rgb_adj[bbox[0] : bbox[2], bbox[1] : bbox[3], :]\n",
    "    crop_seg = seg_soma[bbox[0] : bbox[2], bbox[1] : bbox[3]]\n",
    "    crop_seg = np.repeat(crop_seg[:, :, np.newaxis], 3, axis=2)\n",
    "    crop[crop_seg == 0] = 0\n",
    "\n",
    "    f, axs = plt.subplots(nrows=1, ncols=2, dpi=300)\n",
    "\n",
    "    axs[0].imshow(image_rgb_adj, cmap=\"gray\")\n",
    "    axs[0].set_title(f\"Image {id}\")\n",
    "    axs[1].imshow(crop, cmap=\"gray\")\n",
    "    # axs[1].imshow(seg_cell_masked % 20, cmap=\"tab20\", alpha=1)\n",
    "    # axs[1].imshow(seg_cyto_masked, cmap=\"Accent\", alpha=1)\n",
    "    # axs[1].imshow(seg_nuc_masked > 0, cmap=\"Set1\", alpha=1)\n",
    "\n",
    "    # axs[2].imshow(image_rgb_adj, cmap=\"gray\")\n",
    "    # axs[2].imshow(seg_soma_masked % 20, cmap=\"tab20\", alpha=1)\n",
    "    f.set_figheight(10)\n",
    "    f.set_figwidth(30)\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/first-sample/Assay Dev 20230329/BR00142687__2024-03-29T18_18_57-Measurement 1/stats/Image.csv\",\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/first-sample/Assay Dev 20230329/BR00142688__2024-03-29T19_57_13-Measurement 1/stats/Image.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_exclude = [\n",
    "    \"Metadata_Series\",\n",
    "    \"Metadata_Site\",\n",
    "    \"Metadata_Well\",\n",
    "    \"Metadata_WellColumn\",\n",
    "    \"Metadata_WellRow\",\n",
    "    \"AreaShape_Orientation\",\n",
    "    \"AreaShape_BoundingBoxMaximum_X\",\n",
    "    \"AreaShape_BoundingBoxMaximum_Y\",\n",
    "    \"AreaShape_BoundingBoxMinimum_X\",\n",
    "    \"AreaShape_BoundingBoxMinimum_Y\",\n",
    "    \"AreaShape_Center_X\",\n",
    "    \"AreaShape_Center_Y\",\n",
    "    \"Children_Cytoplasm_Count\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_AGP\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_AGP\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_AGP\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_DNA\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_DNA\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_DNA\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_ER\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_ER\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_ER\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_mito\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_mito\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_mito\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_RNA\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_RNA\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_RNA\",\n",
    "    \"Location_MaxIntensity_X_scaled_DNA\",\n",
    "    \"Location_MaxIntensity_X_scaled_AGP\",\n",
    "    \"Location_MaxIntensity_X_scaled_mito\",\n",
    "    \"Location_MaxIntensity_X_scaled_ER\",\n",
    "    \"Location_Center_X\",\n",
    "    \"Location_Center_Y\",\n",
    "    \"Location_MaxIntensity_X_scaled_RNA\",\n",
    "    \"Location_MaxIntensity_Y_scaled_DNA\",\n",
    "    \"Location_MaxIntensity_Y_scaled_AGP\",\n",
    "    \"Location_MaxIntensity_Y_scaled_mito\",\n",
    "    \"Location_MaxIntensity_Y_scaled_ER\",\n",
    "    \"Location_MaxIntensity_Y_scaled_RNA\",\n",
    "    \"Location_MaxIntensity_Z_scaled_DNA\",\n",
    "    \"Location_MaxIntensity_Z_scaled_AGP\",\n",
    "    \"Location_MaxIntensity_Z_scaled_mito\",\n",
    "    \"Location_MaxIntensity_Z_scaled_ER\",\n",
    "    \"Location_MaxIntensity_Z_scaled_RNA\",\n",
    "    \"Neighbors_AngleBetweenNeighbors_Adjacent\",\n",
    "    \"Neighbors_AngleBetweenNeighbors_25\",\n",
    "    \"Neighbors_FirstClosestObjectNumber_Adjacent\",\n",
    "    \"Neighbors_SecondClosestObjectNumber_Adjacent\",\n",
    "    \"Number_Object_Number\",\n",
    "    \"Parent_EdgeNuclei\",\n",
    "    \"Parent_Nuclei\",\n",
    "    \"Neighbors_FirstClosestObjectNumber_25\",\n",
    "    \"Neighbors_SecondClosestObjectNumber_25\",\n",
    "]\n",
    "\n",
    "\n",
    "def include_feat(feat_name):\n",
    "    for feat_to_exclude in feats_to_exclude:\n",
    "        if feat_to_exclude in feat_name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for i, data_path in enumerate(data_paths):\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    row = [int(fname[1:3]) for fname in list(df[\"FileName_AGP\"])]\n",
    "    col = [int(fname[4:6]) for fname in list(df[\"FileName_AGP\"])]\n",
    "    well = [(i, r, c) for r, c in zip(row, col)]\n",
    "    field = [int(fname[7:9]) for fname in list(df[\"FileName_AGP\"])]\n",
    "    id = [fname[:12] for fname in list(df[\"FileName_AGP\"])]\n",
    "\n",
    "    df[\"Row\"] = row\n",
    "    df[\"Column\"] = col\n",
    "    df[\"Well\"] = well\n",
    "    df[\"Field\"] = field\n",
    "    df[\"ID\"] = id\n",
    "\n",
    "    col_names = list(df.columns)\n",
    "    col_names = [col_name for col_name in col_names if \"Mean_\" in col_name]\n",
    "    col_names = [col_name for col_name in col_names if include_feat(col_name)]\n",
    "    col_names += [\"Plate\", \"Row\", \"Column\", \"Well\", \"Field\", \"ID\"]\n",
    "    print(f\"{len(col_names)} different features\")\n",
    "    df[\"Plate\"] = i\n",
    "    dfs.append(df[col_names])\n",
    "df_means = pd.concat(dfs, axis=\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions = pd.read_excel(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/first-sample/Assay Dev 20230329/Answer ALS_Pilot2_March2024.xlsx\"\n",
    ")\n",
    "df_conditions = df_conditions.iloc[:16, 2:]\n",
    "\n",
    "data_dmso = []\n",
    "data_autophagy = []\n",
    "data_verdinexor = []\n",
    "data_h2o2 = []\n",
    "data_tunicamycin = []\n",
    "data_importazole = []\n",
    "data_celltype = []\n",
    "\n",
    "for i, row in df_means.iterrows():\n",
    "    r = row[\"Row\"] - 1\n",
    "    c = row[\"Column\"] - 1\n",
    "    p = row[\"Plate\"]\n",
    "\n",
    "    condition = df_conditions.iloc[r, c]\n",
    "\n",
    "    if c % 6 == 0:\n",
    "        data_dmso.append(1)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 1:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(1)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 2:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(float(condition))\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 3:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(float(condition))\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 4:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(float(condition))\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 5:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(float(condition))\n",
    "\n",
    "    if p == 0:\n",
    "        if (r < 8 and c < 6) or (r >= 8 and c >= 18):\n",
    "            data_celltype.append(\"Control 1\")\n",
    "        elif (r < 8 and c >= 6 and c < 12) or (r >= 8 and c < 6):\n",
    "            data_celltype.append(\"ALS 1\")\n",
    "        elif (r < 8 and c >= 18) or (r >= 8 and c < 18 and c >= 12):\n",
    "            data_celltype.append(\"Control 2\")\n",
    "        else:\n",
    "            data_celltype.append(\"ALS 2\")\n",
    "    elif p == 1:\n",
    "        if (r < 8 and c < 6) or (r >= 8 and c >= 18):\n",
    "            data_celltype.append(\"ALS 2\")\n",
    "        elif (r < 8 and c >= 6 and c < 12) or (r >= 8 and c < 6):\n",
    "            data_celltype.append(\"Control 2\")\n",
    "        elif (r < 8 and r >= 6 and c >= 18) or (\n",
    "            r >= 8 and r < 10 and c < 18 and c >= 12\n",
    "        ):\n",
    "            data_celltype.append(\"ALS 1\")\n",
    "        elif (r < 8 and c >= 12 and c < 18) or (r >= 8 and c < 12 and c >= 6):\n",
    "            data_celltype.append(\"Control 1\")\n",
    "        else:\n",
    "            data_celltype.append(\"EMPTY\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"DMSO\": data_dmso,\n",
    "    \"Autophagy\": data_autophagy,\n",
    "    \"Verdinexor\": data_verdinexor,\n",
    "    \"H2O2\": data_h2o2,\n",
    "    \"Tunicamysin\": data_tunicamycin,\n",
    "    \"Importazole\": data_importazole,\n",
    "    \"Cell Type\": data_celltype,\n",
    "}\n",
    "df_covariates = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why do we need this?\n",
    "df_covariates.reset_index(drop=True, inplace=True)\n",
    "df_means.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df_means, df_covariates), axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_functions = {k: \"median\" for k in list(df.columns) if \"Mean_\" in k}\n",
    "aggregation_functions_2 = {k: \"first\" for k in list(df.columns) if \"Mean_\" not in k}\n",
    "aggregation_functions.update(aggregation_functions_2)\n",
    "df_agg = df.groupby(df[\"Well\"]).aggregate(aggregation_functions)\n",
    "\n",
    "df_agg.sort_values(by=[\"Cell Type\"], inplace=True)\n",
    "\n",
    "col_names = list(df.columns)\n",
    "col_names = [col_name for col_name in col_names if \"Mean_\" in col_name]\n",
    "print(len(col_names))\n",
    "df_feats_agg = df_agg[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = df_feats_agg.to_numpy()\n",
    "print(f\"Fraction of finite feature values: {np.sum(np.isfinite(feats))/feats.size}\")\n",
    "feats = np.nan_to_num(feats)\n",
    "D = pairwise_distances(feats, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(D, inner_hier_labels=df_agg[\"Cell Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dist = []\n",
    "data_type = []\n",
    "data_ids = []\n",
    "cell_types = df_agg[\"Cell Type\"]\n",
    "\n",
    "for i in range(D.shape[0]):\n",
    "    type1 = cell_types[i]\n",
    "    for j in range(i):\n",
    "        type2 = cell_types[j]\n",
    "        data_dist.append(D[i, j])\n",
    "        data_ids.append((id[i], id[j]))\n",
    "        if type1 == type2:\n",
    "            data_type.append(\"Same\")\n",
    "        else:\n",
    "            data_type.append(\"Different\")\n",
    "\n",
    "df_types = pd.DataFrame(\n",
    "    data={\n",
    "        \"Distance\": data_dist,\n",
    "        \"Cell Type Relationship\": data_type,\n",
    "        \"ID Pair\": data_ids,\n",
    "    }\n",
    ")\n",
    "sns.boxplot(df_types, x=\"Distance\", y=\"Cell Type Relationship\")\n",
    "\n",
    "x = df_types[df_types[\"Cell Type Relationship\"] == \"Same\"][\"Distance\"].to_numpy()\n",
    "y = df_types[df_types[\"Cell Type Relationship\"] == \"Different\"][\"Distance\"].to_numpy()\n",
    "res = mannwhitneyu(x, y, alternative=\"less\")\n",
    "plt.title(\n",
    "    f\"Inter vs. Intra Cell Type Feature Distances (Mann-Whitney p-val: {res.pvalue :.2E})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feats = []\n",
    "data_pvals = []\n",
    "\n",
    "for col in tqdm(list(df_feats_agg.columns)):\n",
    "    x = df_agg[(df_agg[\"Cell Type\"] == \"ALS 1\") | (df_agg[\"Cell Type\"] == \"ALS 2\")][\n",
    "        col\n",
    "    ].to_numpy()\n",
    "    y = df_agg[\n",
    "        (df_agg[\"Cell Type\"] == \"Control 1\") | (df_agg[\"Cell Type\"] == \"Control 2\")\n",
    "    ][col].to_numpy()\n",
    "\n",
    "    x = np.nan_to_num(x).reshape(-1, 1)\n",
    "    y = np.nan_to_num(y).reshape(-1, 1)\n",
    "    res = mannwhitneyu(x, y)\n",
    "\n",
    "    data_feats.append(col)\n",
    "    data_pvals.append(res.pvalue[0])\n",
    "\n",
    "df_pvals = pd.DataFrame(data={\"P-value\": data_pvals, \"Feature\": data_feats})\n",
    "# sns.histplot(df_pvals, x=\"P-value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pvals.sort_values(\"P-value\", inplace=True)\n",
    "df_pvals.to_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/pvals-0.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/D_av.npy\",\n",
    "    D,\n",
    ")\n",
    "\n",
    "df_agg.to_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/df_agg_av.csv\"\n",
    ")\n",
    "\n",
    "with open(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/mapper.pickle\",\n",
    "    \"rb\",\n",
    ") as file:\n",
    "    mapper = pickle.load(file)\n",
    "\n",
    "# mapper = umap.UMAP().fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "df_agg = pd.read_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/df_agg_av.csv\"\n",
    ")\n",
    "D = np.load(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/D_av.npy\",\n",
    ")\n",
    "mapper = umap.UMAP().fit(D)\n",
    "with open(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/mapper.pickle\",\n",
    "    \"wb\",\n",
    ") as handle:\n",
    "    pickle.dump(mapper, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap.plot.points(mapper, labels=df_agg[\"Cell Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert = np.argsort(mapper.embedding_[:, 1])\n",
    "horiz = np.argsort(mapper.embedding_[:, 0])\n",
    "\n",
    "bottom, top = vert[0], vert[-1]\n",
    "left, right = horiz[0], horiz[-1]\n",
    "\n",
    "ax = umap.plot.points(mapper, labels=df_agg[\"Cell Type\"])\n",
    "for extreme in [bottom, top, left, right]:\n",
    "    ax.scatter(mapper.embedding_[extreme, 0], mapper.embedding_[extreme, 1], c=\"blue\")\n",
    "print(df_agg.iloc[top, :][\"ID\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\"r08c17f08p01\", id_to_path_im_1, id_to_path_seg_1)\n",
    "plt.savefig(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/presentation/answer-als/example/example-seg.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extreme in vert[-5:]:\n",
    "    well = df_agg.iloc[extreme, :][\"Well\"]\n",
    "    id = df_agg.iloc[extreme, :][\"ID\"]\n",
    "    print(df_agg.iloc[extreme, :][\"Cell Type\"])\n",
    "    print(well)\n",
    "    if well[0] == 0:\n",
    "        plot(id, id_to_path_im_0, id_to_path_seg_0)\n",
    "    elif well[0] == 1:\n",
    "        plot(id, id_to_path_im_1, id_to_path_seg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extreme in vert[:5]:\n",
    "    well = df_agg.iloc[extreme, :][\"Well\"]\n",
    "    id = df_agg.iloc[extreme, :][\"ID\"]\n",
    "    print(df_agg.iloc[extreme, :][\"Cell Type\"])\n",
    "    print(well)\n",
    "    if well[0] == 0:\n",
    "        plot(id, id_to_path_im_0, id_to_path_seg_0)\n",
    "    elif well[0] == 1:\n",
    "        plot(id, id_to_path_im_1, id_to_path_seg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extreme in [bottom, top, left, right]:\n",
    "    well = df_agg.iloc[extreme, :][\"Well\"]\n",
    "    id = df_agg.iloc[extreme, :][\"ID\"]\n",
    "    if well[0] == 0:\n",
    "        plot(id, id_to_path_im_0, id_to_path_seg_0)\n",
    "    elif well[0] == 1:\n",
    "        plot(id, id_to_path_im_1, id_to_path_seg_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_soma_path = [\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/first-sample/Assay Dev 20230329/BR00142687__2024-03-29T18_18_57-Measurement 1/stats/Somas.csv\",\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/first-sample/Assay Dev 20230329/BR00142688__2024-03-29T19_57_13-Measurement 1/stats/Somas.csv\",\n",
    "]\n",
    "\n",
    "# data_nuc_path = [\n",
    "#     \"/Users/thomasathey/Documents/shavit-lab/fraenkel/first-sample/Assay Dev 20230329/BR00142687__2024-03-29T18_18_57-Measurement 1/stats/Nuclei.csv\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_exclude = [\n",
    "    \"Metadata_Series\",\n",
    "    \"Metadata_Site\",\n",
    "    \"Metadata_Well\",\n",
    "    \"Metadata_WellColumn\",\n",
    "    \"Metadata_WellRow\",\n",
    "    \"AreaShape_Orientation\",\n",
    "    \"AreaShape_BoundingBoxMaximum_X\",\n",
    "    \"AreaShape_BoundingBoxMaximum_Y\",\n",
    "    \"AreaShape_BoundingBoxMinimum_X\",\n",
    "    \"AreaShape_BoundingBoxMinimum_Y\",\n",
    "    \"AreaShape_Center_X\",\n",
    "    \"AreaShape_Center_Y\",\n",
    "    \"Children_Cytoplasm_Count\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_AGP\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_AGP\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_AGP\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_DNA\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_DNA\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_DNA\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_ER\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_ER\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_ER\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_mito\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_mito\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_mito\",\n",
    "    \"Location_CenterMassIntensity_X_scaled_RNA\",\n",
    "    \"Location_CenterMassIntensity_Y_scaled_RNA\",\n",
    "    \"Location_CenterMassIntensity_Z_scaled_RNA\",\n",
    "    \"Location_MaxIntensity_X_scaled_DNA\",\n",
    "    \"Location_MaxIntensity_X_scaled_AGP\",\n",
    "    \"Location_MaxIntensity_X_scaled_mito\",\n",
    "    \"Location_MaxIntensity_X_scaled_ER\",\n",
    "    \"Location_Center_X\",\n",
    "    \"Location_Center_Y\",\n",
    "    \"Location_MaxIntensity_X_scaled_RNA\",\n",
    "    \"Location_MaxIntensity_Y_scaled_DNA\",\n",
    "    \"Location_MaxIntensity_Y_scaled_AGP\",\n",
    "    \"Location_MaxIntensity_Y_scaled_mito\",\n",
    "    \"Location_MaxIntensity_Y_scaled_ER\",\n",
    "    \"Location_MaxIntensity_Y_scaled_RNA\",\n",
    "    \"Location_MaxIntensity_Z_scaled_DNA\",\n",
    "    \"Location_MaxIntensity_Z_scaled_AGP\",\n",
    "    \"Location_MaxIntensity_Z_scaled_mito\",\n",
    "    \"Location_MaxIntensity_Z_scaled_ER\",\n",
    "    \"Location_MaxIntensity_Z_scaled_RNA\",\n",
    "    \"Neighbors_AngleBetweenNeighbors_Adjacent\",\n",
    "    \"Neighbors_AngleBetweenNeighbors_25\",\n",
    "    \"Neighbors_FirstClosestObjectNumber_Adjacent\",\n",
    "    \"Neighbors_SecondClosestObjectNumber_Adjacent\",\n",
    "    \"Number_Object_Number\",\n",
    "    \"Parent_EdgeNuclei\",\n",
    "    \"Parent_Nuclei\",\n",
    "    \"Neighbors_FirstClosestObjectNumber_25\",\n",
    "    \"Neighbors_SecondClosestObjectNumber_25\",\n",
    "]\n",
    "\n",
    "\n",
    "def include_feat(feat_name):\n",
    "    if (\n",
    "        \"Texture\" not in feat_name\n",
    "        and \"AreaShape\" not in feat_name\n",
    "        and \"Intensity\" not in feat_name\n",
    "    ):\n",
    "        return False\n",
    "    for feat_to_exclude in feats_to_exclude:\n",
    "        if feat_to_exclude in feat_name:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i, data_path in enumerate(data_soma_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    object = [item for item in list(df[\"ObjectNumber\"])]\n",
    "    col = [item for item in list(df[\"Metadata_WellColumn\"])]\n",
    "    row = [item for item in list(df[\"Metadata_WellRow\"])]\n",
    "    well = [(i, r, c) for r, c in zip(row, col)]\n",
    "    field = [item for item in list(df[\"Metadata_Site\"])]\n",
    "    id = [\n",
    "        f\"r{str(r).zfill(2)}c{str(c).zfill(2)}f{str(f).zfill(2)}p01\"\n",
    "        for r, c, f in zip(row, col, field)\n",
    "    ]\n",
    "\n",
    "    df[\"Plate\"] = i\n",
    "    df[\"Row\"] = row\n",
    "    df[\"Column\"] = col\n",
    "    df[\"Well\"] = well\n",
    "    df[\"Field\"] = field\n",
    "    df[\"Object\"] = object\n",
    "    df[\"ID\"] = id\n",
    "\n",
    "    col_names = list(df.columns)\n",
    "    col_names = [col_name for col_name in col_names if include_feat(col_name)]\n",
    "    print(f\"{len(col_names)} different features\")\n",
    "    col_names += [\"Plate\", \"Row\", \"Column\", \"Well\", \"Field\", \"Object\", \"ID\"]\n",
    "    dfs.append(df[col_names])\n",
    "df = pd.concat(dfs, axis=\"rows\")\n",
    "\n",
    "# dfs = []\n",
    "# for i, data_path in enumerate(data_nuc_path):\n",
    "#     df = pd.read_csv(data_path)\n",
    "\n",
    "#     object = [item for item in list(df[\"ObjectNumber\"])]\n",
    "#     col = [item for item in list(df[\"Metadata_WellColumn\"])]\n",
    "#     row = [item for item in list(df[\"Metadata_WellRow\"])]\n",
    "#     well = [(i, r, c) for r, c in zip(row, col)]\n",
    "#     field = [item for item in list(df[\"Metadata_Site\"])]\n",
    "#     id = [\n",
    "#         f\"r{str(r).zfill(2)}c{str(c).zfill(2)}f{str(f).zfill(2)}p01\"\n",
    "#         for r, c, f in zip(row, col, field)\n",
    "#     ]\n",
    "\n",
    "#     df[\"Plate\"] = i\n",
    "#     df[\"Row\"] = row\n",
    "#     df[\"Column\"] = col\n",
    "#     df[\"Well\"] = well\n",
    "#     df[\"Field\"] = field\n",
    "#     df[\"Object\"] = object\n",
    "#     df[\"ID\"] = id\n",
    "\n",
    "#     col_names = list(df.columns)\n",
    "#     col_names = [col_name for col_name in col_names if include_feat(col_name)]\n",
    "#     print(f\"{len(col_names)} different features\")\n",
    "#     col_names += [\"Plate\", \"Row\", \"Column\", \"Well\", \"Field\", \"Object\", \"ID\"]\n",
    "#     dfs.append(df[col_names])\n",
    "# df_nucs = pd.concat(dfs, axis=\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/plates.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions = pd.read_excel(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/first-sample/Assay Dev 20230329/Answer ALS_Pilot2_March2024.xlsx\"\n",
    ")\n",
    "df_conditions = df_conditions.iloc[:16, 2:]\n",
    "\n",
    "data_dmso = []\n",
    "data_autophagy = []\n",
    "data_verdinexor = []\n",
    "data_h2o2 = []\n",
    "data_tunicamycin = []\n",
    "data_importazole = []\n",
    "data_celltype = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    r = row[\"Row\"] - 1\n",
    "    c = row[\"Column\"] - 1\n",
    "    p = row[\"Plate\"]\n",
    "\n",
    "    condition = df_conditions.iloc[r, c]\n",
    "\n",
    "    if c % 6 == 0:\n",
    "        data_dmso.append(1)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 1:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(1)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 2:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(float(condition))\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 3:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(float(condition))\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 4:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(float(condition))\n",
    "        data_importazole.append(0)\n",
    "    elif c % 6 == 5:\n",
    "        data_dmso.append(0)\n",
    "        data_autophagy.append(0)\n",
    "        data_verdinexor.append(0)\n",
    "        data_h2o2.append(0)\n",
    "        data_tunicamycin.append(0)\n",
    "        data_importazole.append(float(condition))\n",
    "\n",
    "    if p == 0:\n",
    "        if (r < 8 and c < 6) or (r >= 8 and c >= 18):\n",
    "            data_celltype.append(\"Control 1\")\n",
    "        elif (r < 8 and c >= 6 and c < 12) or (r >= 8 and c < 6):\n",
    "            data_celltype.append(\"ALS 1\")\n",
    "        elif (r < 8 and c >= 18) or (r >= 8 and c < 18 and c >= 12):\n",
    "            data_celltype.append(\"Control 2\")\n",
    "        else:\n",
    "            data_celltype.append(\"ALS 2\")\n",
    "    elif p == 1:\n",
    "        if (r < 8 and c < 6) or (r >= 8 and c >= 18):\n",
    "            data_celltype.append(\"ALS 2\")\n",
    "        elif (r < 8 and c >= 6 and c < 12) or (r >= 8 and c < 6):\n",
    "            data_celltype.append(\"Control 2\")\n",
    "        elif (r < 8 and r >= 6 and c >= 18) or (\n",
    "            r >= 8 and r < 10 and c < 18 and c >= 12\n",
    "        ):\n",
    "            data_celltype.append(\"ALS 1\")\n",
    "        elif (r < 8 and c >= 12 and c < 18) or (r >= 8 and c < 12 and c >= 6):\n",
    "            data_celltype.append(\"Control 1\")\n",
    "        else:\n",
    "            data_celltype.append(\"EMPTY\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"DMSO\": data_dmso,\n",
    "    \"Autophagy\": data_autophagy,\n",
    "    \"Verdinexor\": data_verdinexor,\n",
    "    \"H2O2\": data_h2o2,\n",
    "    \"Tunicamysin\": data_tunicamycin,\n",
    "    \"Importazole\": data_importazole,\n",
    "    \"Cell Type\": data_celltype,\n",
    "}\n",
    "df_covariates = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covariates.to_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/plates-covs.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why do we need this?\n",
    "df_covariates.reset_index(drop=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/plates.csv\"\n",
    ")\n",
    "df_covariates = pd.read_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/plates-covs.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, df_covariates), axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/plates-both.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/plates-both.csv\"\n",
    ")\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Nucleus/Soma Area Ratio\"] = df[\"Mean_Nuclei_AreaShape_Area\"] / df[\"AreaShape_Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df, x=\"Nucleus/Soma Area Ratio\")\n",
    "# sns.histplot(df, x=\"AreaShape_Area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"Nucleus/Soma Area Ratio\"] < 0.9) & (df[\"AreaShape_Area\"] >= 268)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Cell Type\"].unique()\n",
    "df = df[df[\"Cell Type\"] != \"EMPTY\"]\n",
    "df = df[df[\"Verdinexor\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cell Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that labels are consecutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_obj = {}\n",
    "for i, row in tqdm(df_nucs.iterrows()):\n",
    "    id = row[\"ID\"]\n",
    "    obj = row[\"Object\"]\n",
    "\n",
    "    if id in id_to_obj.keys():\n",
    "        new = id_to_obj[id] + [obj]\n",
    "        id_to_obj[id] = new\n",
    "    else:\n",
    "        id_to_obj[id] = [obj]\n",
    "\n",
    "for key, val in id_to_obj.items():\n",
    "    if sorted(val) == list(range(min(val), max(val) + 1)):\n",
    "        pass\n",
    "    else:\n",
    "        print((key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_soma = [f\"{id}-{obj}\" for obj, id in zip(list(df[\"Object\"]), list(df[\"ID\"]))]\n",
    "obj_id_nuc = [\n",
    "    f\"{id}-{obj}\" for obj, id in zip(list(df_nucs[\"Object\"]), list(df_nucs[\"ID\"]))\n",
    "]\n",
    "assert len(obj_id_soma) == len(set(obj_id_soma))\n",
    "assert len(obj_id_nuc) == len(set(obj_id_nuc))\n",
    "\n",
    "for id in obj_id_soma:\n",
    "    if id not in obj_id_nuc:\n",
    "        print(id)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_path_im_0 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142687__2024-03-29T18_18_57-Measurement 1/Images/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")\n",
    "id_to_path_seg_0 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142687__2024-03-29T18_18_57-Measurement 1/segmentations/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")\n",
    "\n",
    "id_to_path_im_1 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142688__2024-03-29T19_57_13-Measurement 1/Images/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")\n",
    "id_to_path_seg_1 = get_id_to_path(\n",
    "    \"/imagestore/Aneesh/Assay Dev 20230329/BR00142688__2024-03-29T19_57_13-Measurement 1/segmentations/\",\n",
    "    tag=\".tif\",\n",
    "    remote=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_segs = id_to_path_seg_0[0][\"r01c01f01p01\"]\n",
    "segs = read_ims(paths_segs, sftp_client=id_to_path_seg_0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(segs[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = True\n",
    "balance = True\n",
    "sample = 10000\n",
    "\n",
    "col_names = list(df.columns)\n",
    "col_names = [col_name for col_name in col_names if include_feat(col_name)]\n",
    "print(len(col_names))\n",
    "\n",
    "if agg:\n",
    "    aggregation_functions = {k: \"mean\" for k in list(df.columns) if include_feat(k)}\n",
    "    aggregation_functions_2 = {\n",
    "        k: \"first\" for k in list(df.columns) if not include_feat(k)\n",
    "    }\n",
    "    aggregation_functions.update(aggregation_functions_2)\n",
    "    df = df.groupby(df[\"Well\"]).aggregate(aggregation_functions)\n",
    "\n",
    "    df.sort_values(by=[\"Cell Type\"], inplace=True)\n",
    "\n",
    "    df_feats = df[col_names]\n",
    "else:\n",
    "    if sample > 0:\n",
    "        if balance:\n",
    "            dfs = []\n",
    "            for type in df[\"Cell Type\"].unique():\n",
    "                dfs.append(df[df[\"Cell Type\"] == type].sample(n=sample // 4))\n",
    "            df = pd.concat(dfs, axis=\"rows\")\n",
    "            df_feats = df[col_names]\n",
    "        else:\n",
    "            df = df.sample(n=sample)\n",
    "            df_feats = df[col_names]\n",
    "    else:\n",
    "        df_feats = df[col_names]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats = (df_feats - df_feats.mean()) / df_feats.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = df_feats.to_numpy()\n",
    "print(f\"Fraction of finite feature values: {np.sum(np.isfinite(feats))/feats.size}\")\n",
    "feats = np.nan_to_num(feats, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "D = pairwise_distances(feats, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = [literal_eval(well) for well in list(df[\"Well\"])]\n",
    "grp = np.array([0 if well[0] == 0 else 1 for well in wells])\n",
    "X = feats\n",
    "y = np.array([0 if \"Control\" in type else 1 for type in list(df[\"Cell Type\"])])\n",
    "\n",
    "X_train = X[grp == 0, :]\n",
    "X_test = X[grp == 1, :]\n",
    "y_train = y[grp == 0]\n",
    "y_test = y[grp == 1]\n",
    "\n",
    "print(f\"train: {X_train.shape} test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "# preprocess dataset, split into training and test part\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.4, random_state=42\n",
    "# )\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf = make_pipeline(StandardScaler(), clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f\"{name}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100, 100)\n",
    "heatmap(a, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate = [w[1] for w in df[\"Well\"]]\n",
    "\n",
    "ax = heatmap(D, outer_hier_labels=df[\"Cell Type\"], inner_hier_labels=plate)\n",
    "# plt.savefig(\"/Users/thomasathey/Documents/shavit-lab/fraenkel/presentation/ljosa-analysis/filter_dead/dist-mat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/D_av.npy\",\n",
    "    D,\n",
    ")\n",
    "\n",
    "df.to_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/df_av.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "D = np.load(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/D_av.npy\",\n",
    ")\n",
    "mapper = umap.UMAP().fit(D)\n",
    "with open(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/mapper.pickle\",\n",
    "    \"wb\",\n",
    ") as handle:\n",
    "    pickle.dump(mapper, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/df_av.csv\"\n",
    ")\n",
    "\n",
    "with open(\n",
    "    \"/Users/thomasathey/Documents/shavit-lab/fraenkel/cell_paint_seg/experiments/mapper.pickle\",\n",
    "    \"rb\",\n",
    ") as file:\n",
    "    mapper = pickle.load(file)\n",
    "\n",
    "# mapper = umap.UMAP().fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = \"Verdinexor\"\n",
    "lvl = 0.02\n",
    "\n",
    "df[condition].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for v, s in zip(df[condition], df[\"Cell Type\"]):\n",
    "    if v > lvl and \"ALS\" in s:\n",
    "        labels.append(f\"ALS x {condition} > {lvl}\")\n",
    "    elif v > lvl and \"Control\" in s:\n",
    "        labels.append(f\"Control x {condition} > {lvl}\")\n",
    "    else:\n",
    "        labels.append(\"Other\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "umap.plot.points(\n",
    "    mapper,\n",
    "    labels=labels,\n",
    "    color_key={\n",
    "        f\"ALS x {condition} > {lvl}\": \"red\",\n",
    "        f\"Control x {condition} > {lvl}\": \"orange\",\n",
    "        \"Other\": \"green\",\n",
    "    },\n",
    ")\n",
    "# umap.plot.points(mapper, labels=df[\"Cell Type\"], color_key={\"ALS 1\": \"red\", \"ALS 2\": \"orange\", \"Control 1\": \"green\", \"Control 2\": \"blue\"})\n",
    "\n",
    "coords = mapper.embedding_\n",
    "group = np.array([0 if \"Control\" in t else 1 for t in df[\"Cell Type\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within = []\n",
    "between = []\n",
    "\n",
    "ctypes = list(df[\"Cell Type\"])\n",
    "\n",
    "for i in range(D.shape[0]):\n",
    "    for j in range(i + 1, D.shape[1]):\n",
    "        dist = D[i, j]\n",
    "        if (\"ALS\" in ctypes[i] and \"ALS\" in ctypes[j]) or (\n",
    "            \"ALS\" not in ctypes[i] and \"ALS\" not in ctypes[j]\n",
    "        ):\n",
    "            within.append(dist)\n",
    "        else:\n",
    "            between.append(dist)\n",
    "\n",
    "mannwhitneyu(within, between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_r = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if include_feat(col):\n",
    "        feat = df[col].to_numpy()\n",
    "        feat = np.nan_to_num(feat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        res = pearsonr(feat, mapper.embedding_[:, 0])\n",
    "        if res.pvalue < 0.05 / 1164 and np.abs(res.statistic) > 0.8:\n",
    "            feat_to_r[col] = res.statistic\n",
    "feat_to_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_r = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if include_feat(col):\n",
    "        feat = df[col].to_numpy()\n",
    "        feat = np.nan_to_num(feat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        res = pearsonr(feat, mapper.embedding_[:, 1])\n",
    "        if res.pvalue < 0.05 / 1164 and np.abs(res.statistic) > 0.7:\n",
    "            feat_to_r[col] = res.statistic\n",
    "feat_to_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert = np.argsort(mapper.embedding_[:, 1])\n",
    "horiz = np.argsort(mapper.embedding_[:, 0])\n",
    "\n",
    "bottom, top = vert[0], vert[-1]\n",
    "left, right = horiz[0], horiz[-1]\n",
    "\n",
    "ax = umap.plot.points(\n",
    "    mapper,\n",
    "    labels=df[\"Cell Type\"],\n",
    "    color_key={\n",
    "        \"ALS 1\": \"red\",\n",
    "        \"ALS 2\": \"orange\",\n",
    "        \"Control 1\": \"green\",\n",
    "        \"Control 2\": \"blue\",\n",
    "    },\n",
    ")\n",
    "extremes = list(horiz[:3]) + list(horiz[-3:])\n",
    "for extreme in extremes:\n",
    "    ax.scatter(mapper.embedding_[extreme, 0], mapper.embedding_[extreme, 1], c=\"purple\")\n",
    "print(df.iloc[top, :][\"ID\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extreme in horiz[-3:]:\n",
    "    well = literal_eval(df.iloc[extreme, :][\"Well\"])\n",
    "    id = df.iloc[extreme, :][\"ID\"]\n",
    "    print(df.iloc[extreme, :][\"Cell Type\"])\n",
    "    print(well)\n",
    "    print(id)\n",
    "    # if well[0] == 0:\n",
    "    #     plot_fields(id, id_to_path_im_0, id_to_path_seg_0)\n",
    "    # elif well[0] == 1:\n",
    "    #     plot_fields(id, id_to_path_im_1, id_to_path_seg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extreme in horiz[:3]:\n",
    "    well = literal_eval(df.iloc[extreme, :][\"Well\"])\n",
    "    id = df.iloc[extreme, :][\"ID\"]\n",
    "    print(df.iloc[extreme, :][\"Cell Type\"])\n",
    "    print(well)\n",
    "    if well[0] == 0:\n",
    "        plot_fields(id, id_to_path_im_0, id_to_path_seg_0)\n",
    "    elif well[0] == 1:\n",
    "        plot_fields(id, id_to_path_im_1, id_to_path_seg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\"r08c17f08p01\", id_to_path_im_1, id_to_path_seg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fields(\"r09c24f01p01\", id_to_path_im_0, id_to_path_seg_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature(\"r01c01f01p01\", id_to_path_im_0, id_to_path_seg_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_crop(\"r07c24f01p01\", id_to_path_im_0, id_to_path_seg_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = df_means.to_numpy()\n",
    "data_mean = np.nan_to_num(data_mean)\n",
    "# data_mean = [row for row, f in zip(data_mean, field) if f != 5]\n",
    "D = pairwise_distances(data_mean, metric=\"cosine\")\n",
    "\n",
    "lim = 9 * 10\n",
    "plt.imshow(D[:lim, :lim])\n",
    "plt.colorbar()\n",
    "\n",
    "for i in np.arange(0, lim, 9):\n",
    "    plt.plot([0, lim], [i - 0.5, i - 0.5], \"r--\", linewidth=0.5)\n",
    "    plt.plot([i - 0.5, i - 0.5], [0, lim], \"r--\", linewidth=0.5)\n",
    "\n",
    "plt.title(\"Feature Cosine Distances between Images (First 90)\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dist = []\n",
    "data_type = []\n",
    "data_ids = []\n",
    "for i in range(D.shape[0]):\n",
    "    tile1 = i // 9\n",
    "    for j in range(i):\n",
    "        tile2 = j // 9\n",
    "        data_dist.append(D[i, j])\n",
    "        data_ids.append((id[i], id[j]))\n",
    "        if tile1 == tile2:\n",
    "            data_type.append(\"Same\")\n",
    "        else:\n",
    "            data_type.append(\"Different\")\n",
    "\n",
    "df_types = pd.DataFrame(\n",
    "    data={\"Distance\": data_dist, \"Well Relationship\": data_type, \"ID Pair\": data_ids}\n",
    ")\n",
    "sns.boxplot(df_types, x=\"Distance\", y=\"Well Relationship\")\n",
    "\n",
    "x = df_types[df_types[\"Well Relationship\"] == \"Same\"][\"Distance\"].to_numpy()\n",
    "y = df_types[df_types[\"Well Relationship\"] == \"Different\"][\"Distance\"].to_numpy()\n",
    "res = mannwhitneyu(x, y, alternative=\"less\")\n",
    "plt.title(\n",
    "    f\"Inter vs. Intrawell Feature Distances (Mann-Whitney p-val: {res.pvalue :.2E})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = df_types[\n",
    "    (df_types[\"Well Relationship\"] == \"Same\") & (df_types[\"Distance\"] > 0.5)\n",
    "]\n",
    "for pair in df_outliers[\"ID Pair\"]:\n",
    "    plot(pair[0], id_to_path_im, id_to_path_seg)\n",
    "    plt.show()\n",
    "    plot(pair[1], id_to_path_im, id_to_path_seg)\n",
    "    plt.show()\n",
    "    print(\"**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Type Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dist = []\n",
    "data_type = []\n",
    "data_ids = []\n",
    "for i in range(D.shape[0]):\n",
    "    type1 = cell_types[i]\n",
    "    for j in range(i):\n",
    "        type2 = cell_types[j]\n",
    "        data_dist.append(D[i, j])\n",
    "        data_ids.append((id[i], id[j]))\n",
    "        if type1 == type2:\n",
    "            data_type.append(\"Same\")\n",
    "        else:\n",
    "            data_type.append(\"Different\")\n",
    "\n",
    "df_types = pd.DataFrame(\n",
    "    data={\n",
    "        \"Distance\": data_dist,\n",
    "        \"Cell Type Relationship\": data_type,\n",
    "        \"ID Pair\": data_ids,\n",
    "    }\n",
    ")\n",
    "sns.boxplot(df_types, x=\"Distance\", y=\"Cell Type Relationship\")\n",
    "\n",
    "x = df_types[df_types[\"Cell Type Relationship\"] == \"Same\"][\"Distance\"].to_numpy()\n",
    "y = df_types[df_types[\"Cell Type Relationship\"] == \"Different\"][\"Distance\"].to_numpy()\n",
    "res = mannwhitneyu(x, y, alternative=\"less\")\n",
    "plt.title(\n",
    "    f\"Inter vs. Intrawell Feature Distances (Mann-Whitney p-val: {res.pvalue :.2E})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrawell distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dist = []\n",
    "data_type = []\n",
    "\n",
    "D_tile = np.zeros((9, 9, D.shape[0] // 9))\n",
    "for i in range(D.shape[0]):\n",
    "    tile1 = i // 9\n",
    "    for j in range(i):\n",
    "        tile2 = j // 9\n",
    "        if tile1 == tile2:\n",
    "            f1 = i % 9\n",
    "            f2 = j % 9\n",
    "            D_tile[f1, f2, tile1] = D[i, j]\n",
    "\n",
    "\n",
    "D_tile2 = np.zeros((9, (D.shape[0] // 9) * 8))\n",
    "for field in range(D_tile2.shape[0]):\n",
    "    distances = []\n",
    "    for i in range(1, D_tile.shape[0]):\n",
    "        for j in range(i):\n",
    "            if i == field or j == field:\n",
    "                distances += list(D_tile[i, j, :])\n",
    "\n",
    "    D_tile2[field, :] = distances\n",
    "\n",
    "dfs = []\n",
    "for field in range(D_tile2.shape[0]):\n",
    "    df = pd.DataFrame({\"Distance\": D_tile2[field, :]})\n",
    "    df[\"Field\"] = str(field)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "sns.boxplot(df, x=\"Distance\", y=\"Field\")\n",
    "plt.title(\"Distances from Other Fields of Same Well\")\n",
    "\n",
    "# # f, axs = plt.subplots(nrows=9, ncols=9)\n",
    "# # for i, row in enumerate(axs):\n",
    "# #     for j, ax in enumerate(row):\n",
    "# #         sns.histplot(D_tile[i,j,:], ax=ax)\n",
    "# #         ax.set_xlim(left=0, right=1)\n",
    "\n",
    "# # f.set_size_inches(20,20)\n",
    "\n",
    "# f, axs = plt.subplots(ncols=9)\n",
    "# for i, ax in enumerate(axs):\n",
    "#     sns.histplot(D_tile2[i,:], ax=ax)\n",
    "#     ax.set_xlim(left=0, right=1)\n",
    "# f.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
